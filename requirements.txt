# NFL Data Engineering Pipeline - Local Development + S3 Integration
# Updated for your infrastructure: nfl-raw, nfl-refined, nfl-trusted buckets in us-east-2
# MCP Integration: Filesystem, Sequential Thinking, and Puppeteer MCPs configured

# Primary data source library
nfl-data-py>=0.3.3

# AWS SDK for Python - Essential for S3 integration
boto3>=1.26.0
botocore>=1.29.0

# Core data processing libraries for local development
pandas>=1.3.0
numpy>=1.21.0

# PySpark for local Spark development (optional - for Databricks compatibility)
pyspark>=3.2.0
# Note: Remove pyspark if memory constraints exist in local environment

# Data format support
pyarrow>=10.0.0  # For Parquet file handling with S3
fastparquet>=0.8.0  # Alternative Parquet engine

# Web scraping support (used by Puppeteer MCP)
requests>=2.28.0
beautifulsoup4>=4.11.0
selenium>=4.0.0  # Backup for web automation

# Environment and configuration management
python-dotenv>=0.19.0
pyyaml>=6.0.0

# Testing framework
pytest>=7.0.0
pytest-cov>=4.0.0
moto>=4.0.0  # Mock AWS services for testing

# Data validation and quality (optional)
great-expectations>=0.15.0
jsonschema>=4.0.0

# Logging and monitoring
structlog>=22.0.0

# Development and code quality
black>=22.0.0  # Code formatting
flake8>=5.0.0  # Linting
isort>=5.10.0  # Import sorting

# Future Databricks integration (when upgrading)
# databricks-connect>=11.3.0  # Uncomment when upgrading to Databricks Standard+
# delta-spark>=2.1.0  # Uncomment for Delta Lake support

# Note: MCP servers are installed via npm globally:
# npm install -g @modelcontextprotocol/server-filesystem
# npm install -g @modelcontextprotocol/server-sequential-thinking
# npm install -g puppeteer-mcp-server